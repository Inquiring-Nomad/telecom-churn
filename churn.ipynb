{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV,cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix,  roc_curve, precision_recall_curve, accuracy_score, roc_auc_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from autoviz.AutoViz_Class import AutoViz_Class\n",
    "from pandas_profiling import ProfileReport\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_analysis(y_true, y_pred, labels, ymap=None, figsize=(10,10)):\n",
    "    \"\"\"\n",
    "    Generate matrix plot of confusion matrix with pretty annotations.\n",
    "    The plot image is saved to disk.\n",
    "    args: \n",
    "      y_true:    true label of the data, with shape (nsamples,)\n",
    "      y_pred:    prediction of the data, with shape (nsamples,)\n",
    "      filename:  filename of figure file to save\n",
    "      labels:    string array, name the order of class labels in the confusion matrix.\n",
    "                 use `clf.classes_` if using scikit-learn models.\n",
    "                 with shape (nclass,).\n",
    "      ymap:      dict: any -> string, length == nclass.\n",
    "                 if not None, map the labels & ys to more understandable strings.\n",
    "                 Caution: original y_true, y_pred and labels must align.\n",
    "      figsize:   the size of the figure plotted.\n",
    "    \"\"\"\n",
    "    if ymap is not None:\n",
    "        y_pred = [ymap[yi] for yi in y_pred]\n",
    "        y_true = [ymap[yi] for yi in y_true]\n",
    "        labels = [ymap[yi] for yi in labels]\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, annot=annot, fmt='', ax=ax)\n",
    "#     plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATASET = os.path.join('data','Telecomms-Churn.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = DATASET\n",
    "sep = \",\"\n",
    "AV = AutoViz_Class()\n",
    "dft = AV.AutoViz(\n",
    "    filename,\n",
    "    sep=\",\",\n",
    "    depVar=\"Churn\",\n",
    "    dfte=None,\n",
    "    header=0,\n",
    "    verbose=0,\n",
    "    lowess=False,\n",
    "    chart_format=\"svg\",\n",
    "    max_rows_analyzed=150000,\n",
    "    max_cols_analyzed=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "profile = ProfileReport(df,explorative=True)\n",
    "profile.to_file('churn-eda.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalCharges'] = df['TotalCharges'].replace(\" \", 0).astype('float64')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Churn'].replace(to_replace = {'Yes': 1, 'No': 0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['customerID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary categorical variables that are text\n",
    "binary_vars = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']\n",
    "binary_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non Binary categorical variables that are text\n",
    "# categ_vars = [col for col in (df.nunique()[(df.nunique() > 2) & (df.dtypes == np.object)] ).index]\n",
    "categ_vars = ['gender','MultipleLines',\n",
    " 'InternetService',\n",
    " 'OnlineSecurity',\n",
    " 'OnlineBackup',\n",
    " 'DeviceProtection',\n",
    " 'TechSupport',\n",
    " 'StreamingTV',\n",
    " 'StreamingMovies',\n",
    " 'Contract',\n",
    " 'PaymentMethod']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numeric variables\n",
    "\n",
    "numeric_vars = ['tenure','MonthlyCharges','TotalCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler,FunctionTransformer,OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator,TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBinaryTransformer(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        \n",
    "        return X.replace(to_replace = {'Yes': 1, 'No': 0} )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\",StandardScaler(),numeric_vars),\n",
    "    (\"cat_vars\",OneHotEncoder(),categ_vars),\n",
    "    (\"bin_vars\",CustomBinaryTransformer(),binary_vars)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Churn',axis=1)\n",
    "y = df.iloc[:,-1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "X_train, X_test,y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_proc = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier,RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,confusion_matrix,plot_confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###RANDOM FOREST###\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier()\n",
    "forest_clf.fit(X_train_proc,y_train)\n",
    "y_train_forest_scores = cross_val_score(forest_clf,X_train_proc,y_train,cv=5,scoring=\"accuracy\")\n",
    "y_train_forest_pred = cross_val_predict(forest_clf,X_train_proc,y_train,cv=5,method='predict')\n",
    "print(f'Mean Scores:{np.array(y_train_forest_scores).mean()}')\n",
    "print(f'F1 Score: {f1_score(y_train, y_train_forest_pred)}')\n",
    "print(classification_report(y_train, y_train_forest_pred))\n",
    "features = X.columns\n",
    "importances = forest_clf.feature_importances_\n",
    "sorted(zip(importances,features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_analysis(y_train,y_train_forest_pred,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###NAIVE BAYES###\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nv_bs = GaussianNB()\n",
    "y_train_nv_scores=cross_val_score(nv_bs,X_train_proc,y_train,cv=5,scoring=\"accuracy\")\n",
    "y_train_nv_pred = cross_val_predict(nv_bs,X_train_proc,y_train,cv=5,method='predict')\n",
    "print(f'Mean Scores:{np.array(y_train_nv_scores).mean()}')\n",
    "print(f'F1 Score: {f1_score(y_train, y_train_nv_pred)}')\n",
    "print(confusion_matrix(y_train,y_train_nv_pred))\n",
    "print(classification_report(y_train, y_train_nv_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kn = KNeighborsClassifier(n_neighbors=10)\n",
    "y_train_kn_scores=cross_val_score(kn,X_train_proc,y_train,cv=5,scoring=\"accuracy\")\n",
    "y_train_kn_pred = cross_val_predict(kn,X_train_proc,y_train,cv=5,method='predict')\n",
    "print(f'Mean Scores:{np.array(y_train_kn_scores).mean()}')\n",
    "print(f'F1 Score: {f1_score(y_train, y_train_kn_pred)}')\n",
    "print(confusion_matrix(y_train,y_train_kn_pred))\n",
    "print(classification_report(y_train, y_train_kn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logR = LogisticRegression(C=0.1)\n",
    "y_train_logR_scores=cross_val_score(logR,X_train_proc,y_train,cv=5,scoring=\"accuracy\")\n",
    "y_train_logR_pred = cross_val_predict(logR,X_train_proc,y_train,cv=5,method='predict')\n",
    "print(f'Mean Scores:{np.array(y_train_logR_scores).mean()}')\n",
    "print(f'F1 Score: {f1_score(y_train, y_train_logR_pred)}')\n",
    "print(confusion_matrix(y_train,y_train_logR_pred))\n",
    "print(classification_report(y_train, y_train_logR_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "###VOTING CLASSIFIER###\n",
    "clf1 = XGBClassifier()\n",
    "clf2 = RandomForestClassifier(n_estimators=50)\n",
    "clf3 = GaussianNB()\n",
    "clf4 =  LogisticRegression(C=0.1)\n",
    "\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('xgb', clf1), ('rf', clf2), ('gnb', clf3),('logR',clf4)],\n",
    "    voting='hard')\n",
    "\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3,clf4, eclf], ['XGBoost', 'Random Forest', 'naive Bayes','logistic Reg' ,'Ensemble']):\n",
    "    scores = cross_val_score(clf, X_train_proc, y_train, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid={\"C\":np.logspace(-10,-3,3,10), \"penalty\":[\"l1\",\"l2\"]}\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(X_train_proc,y_train)\n",
    "\n",
    "print(\"Best Params \",logreg_cv.best_params_)\n",
    "print(\"Best Accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_best_log_pred = cross_val_predict(logreg_cv.best_estimator_, X_train_proc, y_train)\n",
    "\n",
    "print(f'F1 Score: {f1_score(y_train, y_best_log_pred)}')\n",
    "print(confusion_matrix(y_train,y_best_log_pred))\n",
    "print(classification_report(y_train, y_best_log_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [forest_clf,nv_bs,kn,logR,eclf]\n",
    "X_test_proc = preprocessor.fit_transform(X_test)\n",
    "for classifier in classifiers:\n",
    "    name = classifier.__class__.__name__\n",
    "    \n",
    "    y_pred = classifier.predict(X_test_proc)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    print(\"-\"*30)\n",
    "    print(name + \":\")\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logR.fit(X_train_proc,y_train)\n",
    "X_test_proc = preprocessor.fit_transform(X_test)\n",
    "logR_test_pred = logR.predict(X_test_proc)\n",
    "acc = accuracy_score(y_test,logR_test_pred)\n",
    "print(\"-\"*30)\n",
    "print(\"Log Reg:\")\n",
    "print(\"Accuracy: {:.4%}\".format(acc))\n",
    "print(confusion_matrix(y_test,logR_test_pred))\n",
    "print(classification_report(y_test, logR_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_analysis(y_test,logR_test_pred,np.array([0, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}